#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MangaVega Tracker - Synchronisation Gist et fichiers de configuration
"""

import json
import os
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List

import config
from utils import strip_type_suffix

logger = config.logger


def sauvegarder_gist_config():
    """
    Sauvegarde series_config.json et corrections.json vers le Gist GitHub.
    Met √† jour date_seuil pour le prochain run.
    """
        
    if not config.GIST_TOKEN:
        logger.warning("   ‚ö†Ô∏è  Pas de token GitHub, impossible de sauvegarder le Gist")
        return False
    
    try:
        import urllib.request
        
        # Mettre √† jour date_seuil : date d'aujourd'hui - 14 jours de marge
        # La marge permet de re-d√©tecter un volume qui appara√Ætrait r√©troactivement
        nouvelle_date_seuil = (datetime.now() - timedelta(days=14)).strftime('%Y-%m-%d')
        config.GIST_CORRECTIONS['date_seuil'] = nouvelle_date_seuil
        
        logger.info(f"‚òÅÔ∏è  Sauvegarde du Gist...")
        logger.info(f"   üìÖ Nouvelle date seuil: {nouvelle_date_seuil}")
        
        # Pr√©parer les donn√©es √† envoyer
        files_to_update = {
            "corrections.json": {
                "content": json.dumps(config.GIST_CORRECTIONS, ensure_ascii=False, indent=2)
            }
        }
        
        # Ajouter series_config.json seulement si modifi√©
        if config.GIST_MODIFIED:
            files_to_update["series_config.json"] = {
                "content": json.dumps(config.GIST_SERIES_CONFIG, ensure_ascii=False, indent=2)
            }
        
        data = { "files": files_to_update }
        
        req = urllib.request.Request(
            config.GIST_API_URL,
            data=json.dumps(data).encode('utf-8'),
            headers={
                'User-Agent': 'MangaTracker/1.0',
                'Authorization': f'token {config.GIST_TOKEN}',
                'Content-Type': 'application/json'
            },
            method='PATCH'
        )
        
        with urllib.request.urlopen(req, timeout=10) as response:
            if response.status == 200:
                logger.info("   ‚úÖ Gist mis √† jour avec succ√®s")
                config.GIST_MODIFIED = False
                return True
        
        return False
        
    except Exception as e:
        logger.warning(f"   ‚ö†Ô∏è  Erreur sauvegarde Gist: {e}")
        return False

def charger_gist_config():
    """
    Charge corrections.json et series_config.json depuis le Gist GitHub.
    Ces fichiers sont synchronis√©s par le viewer web.
    
    Returns:
        tuple: (corrections_dict, series_config_dict)
    """
            
    try:
        import urllib.request
        
        logger.info("‚òÅÔ∏è  Chargement de la configuration depuis le Gist...")
        
        req = urllib.request.Request(config.GIST_API_URL, headers={'User-Agent': 'MangaTracker/1.0'})
        with urllib.request.urlopen(req, timeout=10) as response:
            gist_data = json.loads(response.read().decode('utf-8'))
        
        files = gist_data.get('files', {})
        
        # Charger corrections.json
        if 'corrections.json' in files:
            content = files['corrections.json'].get('content', '{}')
            config.GIST_CORRECTIONS = json.loads(content)
            nb_valides = len(config.GIST_CORRECTIONS.get('valides', []))
            nb_rejetes = len(config.GIST_CORRECTIONS.get('rejetes', []))
            logger.info(f"   ‚úÖ corrections.json: {nb_valides} valid√©(s), {nb_rejetes} rejet√©(s)")
            
            # Charger date_seuil dynamique
            if 'date_seuil' in config.GIST_CORRECTIONS:
                try:
                    config.DATE_SEUIL = datetime.strptime(config.GIST_CORRECTIONS['date_seuil'], '%Y-%m-%d')
                    logger.info(f"   üìÖ Date seuil nouveaut√©s: {config.DATE_SEUIL.strftime('%Y/%m/%d')} (depuis Gist)")
                except (ValueError, TypeError):
                    logger.warning(f"   ‚ö†Ô∏è  Date seuil invalide dans Gist: {config.GIST_CORRECTIONS['date_seuil']}, utilisation d√©faut")
            else:
                logger.info(f"   üìÖ Date seuil nouveaut√©s: {config.DATE_SEUIL.strftime('%Y/%m/%d')} (d√©faut, premier run)")
        
        # Charger series_config.json
        if 'series_config.json' in files:
            content = files['series_config.json'].get('content', '{}')
            config.GIST_SERIES_CONFIG = json.loads(content)
            nb_urls = sum(len(urls) for urls in config.GIST_SERIES_CONFIG.get('urls_supplementaires', {}).values())
            nb_ajoutees = len(config.GIST_SERIES_CONFIG.get('series_ajoutees', []))
            logger.info(f"   ‚úÖ series_config.json: {nb_urls} URL(s) supp., {nb_ajoutees} s√©rie(s) ajout√©e(s)")
        
        return config.GIST_CORRECTIONS, config.GIST_SERIES_CONFIG
        
    except Exception as e:
        logger.warning(f"   ‚ö†Ô∏è  Impossible de charger le Gist: {e}")
        return {}, {}

def charger_corrections(db: 'DatabaseManager' = None):
    """
    Charge les corrections depuis le Gist, la BDD et/ou le fichier corrections.json.
    
    Priorit√©:
    1. Charge depuis le Gist (synchronis√© par le viewer)
    2. Importe corrections.json vers la BDD (si pr√©sent)
    3. Charge les ASINs rejet√©s depuis la BDD
    """
        
    # Si on a un db manager, utiliser la BDD
    if db:
        # NOUVEAU: Importer les rejets du Gist vers la BDD
        if config.GIST_CORRECTIONS:
            gist_rejetes = config.GIST_CORRECTIONS.get('rejetes', [])
            gist_valides = config.GIST_CORRECTIONS.get('valides', [])
            gist_tomes = config.GIST_CORRECTIONS.get('tomes', {})
            
            if gist_rejetes or gist_valides:
                # Comparer avec les statuts existants pour ne pas re-importer
                existing_rejetes = db.get_asins_rejetes()
                existing_valides = db.get_asins_valides()
                
                # Importer seulement les nouveaux
                imported_rejets = 0
                imported_valides = 0
                for asin in gist_rejetes:
                    if asin not in existing_rejetes:
                        db.set_statut_manuel(asin, 'rejete', 'Import Gist')
                        imported_rejets += 1
                for asin in gist_valides:
                    if asin not in existing_valides:
                        db.set_statut_manuel(asin, 'valide', 'Import Gist')
                        imported_valides += 1
                if imported_rejets > 0:
                    logger.info(f"‚òÅÔ∏è  {imported_rejets} nouveau(x) rejet(s) import√©(s) depuis Gist")
                if imported_valides > 0:
                    logger.info(f"‚òÅÔ∏è  {imported_valides} nouvelle(s) validation(s) import√©e(s) depuis Gist")
            
            # Importer les corrections de tomes
            if gist_tomes:
                imported_tomes = 0
                for asin, tome in gist_tomes.items():
                    try:
                        db.update_tome_volume(asin, int(tome))
                        imported_tomes += 1
                    except Exception as e:
                        logger.debug(f"‚ö†Ô∏è Erreur import tome {asin}: {e}")
                if imported_tomes > 0:
                    logger.info(f"‚òÅÔ∏è  {imported_tomes} correction(s) de tome import√©e(s) depuis Gist")
            
            # Importer les √©diteurs officiels du Gist vers la BDD
            gist_editeurs = config.GIST_CORRECTIONS.get('editeurs_officiels', {})
            if gist_editeurs:
                imported_editeurs = 0
                for serie_jp, editeur in gist_editeurs.items():
                    editeur_actuel = db.get_editeur_officiel(serie_jp)
                    if editeur_actuel != editeur:
                        db.set_editeur_officiel(serie_jp, editeur)
                        imported_editeurs += 1
                if imported_editeurs > 0:
                    logger.info(f"‚òÅÔ∏è  {imported_editeurs} √©diteur(s) officiel(s) import√©(s) depuis Gist")
                else:
                    logger.info(f"üìö {len(gist_editeurs)} √©diteur(s) officiel(s) (√† jour)")
        
        # Importer corrections.json vers la BDD s'il existe (fichier local)
        if os.path.exists(config.CORRECTIONS_FILE):
            counts = db.importer_statuts_json(config.CORRECTIONS_FILE)
            has_imports = counts['rejetes'] > 0 or counts['overrides'] > 0 or counts['scissions'] > 0
            if has_imports:
                if counts['rejetes'] > 0:
                    logger.info(f"üìã {counts['rejetes']} rejet(s) import√©(s) depuis {config.CORRECTIONS_FILE}")
                if counts['overrides'] > 0:
                    logger.info(f"üîÄ {counts['overrides']} override(s) de s√©rie import√©(s)")
                if counts['scissions'] > 0:
                    logger.info(f"‚úÇÔ∏è {counts['scissions']} s√©rie(s) scind√©e(s) import√©e(s)")
                # Renommer le fichier pour √©viter de re-importer
                backup_name = f"corrections_imported_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                os.rename(config.CORRECTIONS_FILE, backup_name)
                logger.info(f"   ‚Üí Fichier renomm√© en {backup_name}")
        
        # Charger depuis la BDD
        config.ASINS_HORS_SUJET = db.get_asins_rejetes()
        if config.ASINS_HORS_SUJET:
            logger.info(f"üö´ {len(config.ASINS_HORS_SUJET)} ASIN(s) marqu√©(s) hors-sujet (depuis BDD)")
    else:
        # Fallback : charger directement depuis le fichier JSON
        if os.path.exists(config.CORRECTIONS_FILE):
            try:
                with open(config.CORRECTIONS_FILE, 'r', encoding='utf-8') as f:
                    corrections = json.load(f)
                config.ASINS_HORS_SUJET = set(corrections.get('hors_sujet', []))
                if config.ASINS_HORS_SUJET:
                    logger.info(f"üìã {len(config.ASINS_HORS_SUJET)} ASIN(s) hors-sujet (depuis {config.CORRECTIONS_FILE})")
            except (json.JSONDecodeError, IOError) as e:
                logger.warning(f"‚ö†Ô∏è  Erreur lecture {config.CORRECTIONS_FILE}: {e}")



def charger_mangas_liste():
    """
    Charge la liste des mangas depuis mangas_liste.json.
    Ce fichier est la source principale et peut √™tre modifi√© par le Gist.
    
    Returns:
        list: Liste des mangas √† surveiller
    """
        
    if not os.path.exists(config.MANGAS_LISTE_FILE):
        logger.error(f"‚ùå {config.MANGAS_LISTE_FILE} non trouv√© ! Ce fichier est obligatoire.")
        logger.error(f"   Cr√©ez-le avec le format: {{\"mangas\": [{{\"nom\": \"...\", \"url_suffix\": \"...\"}}]}}")
        return config.MANGAS_A_SUIVRE
    
    try:
        with open(config.MANGAS_LISTE_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        mangas = data.get('mangas', [])
        if mangas:
            # Convertir type ‚Üí filtre (ex: type="ln" ‚Üí filtre="ln_only")
            for manga in mangas:
                if not manga.get('filtre') and manga.get('type'):
                    type_serie = manga['type']
                    if type_serie == 'ln':
                        manga['filtre'] = 'ln_only'
                    elif type_serie == 'manga':
                        manga['filtre'] = 'manga_only'
            config.MANGAS_A_SUIVRE = mangas
            logger.info(f"üìã {len(mangas)} s√©rie(s) charg√©e(s) depuis {config.MANGAS_LISTE_FILE}")
        return config.MANGAS_A_SUIVRE
        
    except (json.JSONDecodeError, IOError) as e:
        logger.warning(f"‚ö†Ô∏è  Erreur lecture {config.MANGAS_LISTE_FILE}: {e}")
        return config.MANGAS_A_SUIVRE


def sauvegarder_mangas_liste():
    """
    Sauvegarde la liste des mangas dans mangas_liste.json.
    Appel√© apr√®s modification via le Gist (ajout/suppression).
    """
    try:
        # IMPORTANT: Ne persister que les cl√©s structurelles (pas urls_supplementaires, asin_reference, etc.)
        mangas_clean = []
        for m in config.MANGAS_A_SUIVRE:
            mangas_clean.append({k: v for k, v in m.items() if k in config.CLES_PERSISTEES_MANGA and v})
        
        data = {
            "version": "2.0",
            "description": "MangaVega Tracker - Liste des s√©ries √† surveiller",
            "last_updated": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "mangas": mangas_clean
        }
        
        with open(config.MANGAS_LISTE_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üíæ Liste sauvegard√©e dans {config.MANGAS_LISTE_FILE} ({len(config.MANGAS_A_SUIVRE)} s√©ries)")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur sauvegarde {config.MANGAS_LISTE_FILE}: {e}")
        return False



def charger_series_config(db: 'DatabaseManager' = None):
    """
    Charge series_config.json depuis le Gist et/ou le fichier local,
    puis fusionne les URLs suppl√©mentaires dans config.MANGAS_A_SUIVRE.
    
    Le fichier peut contenir:
    - urls_supplementaires: {serie_jp: [url1, url2, ...]}
    - series_ajoutees: nouvelles s√©ries √† ajouter (int√©gr√©es √† mangas_liste.json)
    - series_supprimees: s√©ries √† retirer (retir√©es de mangas_liste.json)
    - traductions: {serie_jp: titre_fr}
    
    NOUVEAU: Les s√©ries ajout√©es/supprim√©es modifient mangas_liste.json directement.
    """
        
    modifs = 0
    liste_modifiee = False  # Flag pour savoir si on doit sauvegarder mangas_liste.json
    
    # ====== √âTAPE 1: Charger depuis le Gist (prioritaire) ======
    if config.GIST_SERIES_CONFIG:
        gist_urls = config.GIST_SERIES_CONFIG.get('urls_supplementaires', {})
        gist_added = config.GIST_SERIES_CONFIG.get('series_ajoutees', [])
        gist_removed = config.GIST_SERIES_CONFIG.get('series_supprimees', [])
        
        # 1a. Fusionner les URLs suppl√©mentaires du Gist
        if gist_urls:
            for manga in config.MANGAS_A_SUIVRE:
                nom = manga.get('nom', '')
                if nom in gist_urls:
                    existing_urls = manga.get('urls_supplementaires', [])
                    new_urls = gist_urls[nom]
                    # Fusionner sans doublons
                    all_urls = list(set(existing_urls + new_urls))
                    if all_urls:
                        manga['urls_supplementaires'] = all_urls
                        logger.info(f"‚òÅÔ∏è  {len(new_urls)} URL(s) supp. (Gist) pour: {nom[:30]}...")
                        modifs += len(new_urls)
        
        # 1b. Retirer les s√©ries supprim√©es du Gist ‚Üí RETIR√âES DE mangas_liste.json
        # (AVANT l'ajout, pour permettre supprimer+r√©ajouter dans le m√™me run = purge du cache)
        if gist_removed:
            # Filtrer les entr√©es vides
            gist_removed = [s for s in gist_removed if s and s.strip()]
            
            if gist_removed:
                before = len(config.MANGAS_A_SUIVRE)
                # Matcher les noms exacts (avec suffixe) OU les noms de base (compatibilit√©)
                # Le viewer envoie le nom complet avec [LN]/[MANGA]
                noms_a_retirer = set(gist_removed)
                config.MANGAS_A_SUIVRE = [m for m in config.MANGAS_A_SUIVRE 
                                   if m['nom'] not in noms_a_retirer]
                removed_count = before - len(config.MANGAS_A_SUIVRE)
                if removed_count > 0:
                    logger.info(f"‚òÅÔ∏è  {removed_count} s√©rie(s) retir√©e(s) (Gist)")
                    modifs += removed_count
                    liste_modifiee = True
                    
                    # Purger le cache BDD ET le Gist pour les s√©ries supprim√©es
                    if db:
                        for nom_serie in gist_removed:
                            try:
                                # R√©cup√©rer les ASIN AVANT la purge (pour nettoyer le Gist)
                                asins_serie = db.get_asins_serie(nom_serie)
                                
                                # Purger la BDD
                                db.purger_serie(nom_serie)
                                
                                # Nettoyer le Gist : retirer les ASIN de valides/rejetes/tomes
                                if asins_serie and config.GIST_CORRECTIONS:
                                    before_v = len(config.GIST_CORRECTIONS.get('valides', []))
                                    before_r = len(config.GIST_CORRECTIONS.get('rejetes', []))
                                    
                                    config.GIST_CORRECTIONS['valides'] = [
                                        a for a in config.GIST_CORRECTIONS.get('valides', []) 
                                        if a not in asins_serie
                                    ]
                                    config.GIST_CORRECTIONS['rejetes'] = [
                                        a for a in config.GIST_CORRECTIONS.get('rejetes', []) 
                                        if a not in asins_serie
                                    ]
                                    # Nettoyer les tomes
                                    for asin in asins_serie:
                                        config.GIST_CORRECTIONS.get('tomes', {}).pop(asin, None)
                                    
                                    removed_v = before_v - len(config.GIST_CORRECTIONS.get('valides', []))
                                    removed_r = before_r - len(config.GIST_CORRECTIONS.get('rejetes', []))
                                    if removed_v + removed_r > 0:
                                        logger.info(f"   ‚òÅÔ∏è  Gist nettoy√©: {removed_v} valid√©(s), {removed_r} rejet√©(s) retir√©s")
                                
                                # Nettoyer l'√©diteur officiel du Gist
                                if config.GIST_CORRECTIONS and nom_serie in config.GIST_CORRECTIONS.get('editeurs_officiels', {}):
                                    del config.GIST_CORRECTIONS['editeurs_officiels'][nom_serie]
                                    logger.info(f"   ‚òÅÔ∏è  √âditeur officiel retir√© du Gist")
                                    
                            except Exception as e:
                                logger.error(f"‚ùå Erreur purge s√©rie '{nom_serie}': {e}")
                
                # Vider series_supprimees apr√®s traitement
                config.GIST_SERIES_CONFIG['series_supprimees'] = []
                config.GIST_MODIFIED = True
                logger.info(f"   üßπ S√©ries retir√©es de {config.MANGAS_LISTE_FILE}, series_supprimees vid√©")
        
        # 1c. Ajouter les nouvelles s√©ries du Gist ‚Üí INT√âGR√âES √Ä mangas_liste.json
        if gist_added:
            for serie in gist_added:
                nom = serie.get('nom', '')
                url = serie.get('url', '')
                type_serie = serie.get('type', '')  # "ln", "manga", ou vide
                
                # Suffixe syst√©matique [LN] ou [MANGA] pour le nom interne
                nom_interne = nom
                if not nom.endswith(' [LN]') and not nom.endswith(' [MANGA]'):
                    if type_serie == 'ln':
                        nom_interne = f"{nom} [LN]"
                    else:
                        nom_interne = f"{nom} [MANGA]"
                
                if nom and not any(m['nom'] == nom_interne for m in config.MANGAS_A_SUIVRE):
                    
                    # PURGE AUTOMATIQUE : si un vieux cache existe pour cette s√©rie, le nettoyer
                    # (cas suppression + r√©-ajout, ou purge √©chou√©e au run pr√©c√©dent)
                    if db:
                        cache_existant = db.get_volumes_connus(nom_interne)
                        if cache_existant:
                            try:
                                asins_serie = db.get_asins_serie(nom_interne)
                                db.purger_serie(nom_interne)
                                
                                # Nettoyer le Gist aussi
                                if asins_serie and config.GIST_CORRECTIONS:
                                    config.GIST_CORRECTIONS['valides'] = [
                                        a for a in config.GIST_CORRECTIONS.get('valides', [])
                                        if a not in asins_serie
                                    ]
                                    config.GIST_CORRECTIONS['rejetes'] = [
                                        a for a in config.GIST_CORRECTIONS.get('rejetes', [])
                                        if a not in asins_serie
                                    ]
                                    for asin in asins_serie:
                                        config.GIST_CORRECTIONS.get('tomes', {}).pop(asin, None)
                                    config.GIST_CORRECTIONS.get('editeurs_officiels', {}).pop(nom_interne, None)
                                
                                logger.info(f"   üóëÔ∏è  Cache + Gist purg√©s pour {nom_interne[:30]} (r√©-ajout)")
                            except Exception as e:
                                logger.error(f"‚ùå Erreur purge (r√©-ajout) '{nom_interne}': {e}")
                    
                    new_serie = {
                        'nom': nom_interne,
                        'url_suffix': serie.get('url_suffix', nom),  # Recherche Amazon = titre original (sans [LN])
                        'urls_supplementaires': []
                    }
                    
                    # Log si le nom de recherche diff√®re
                    if new_serie['url_suffix'] != nom:
                        logger.info(f"   üîç Nom de recherche: {new_serie['url_suffix']}")
                    
                    # Sauvegarder les traductions FR/EN si fournies
                    nom_fr = serie.get('nom_fr', '')
                    nom_en = serie.get('nom_en', '')
                    if nom_fr or nom_en:
                        if db:
                            db.sauvegarder_traduction_complete(
                                nom_interne, 
                                titre_francais=nom_fr or None, 
                                titre_anglais=nom_en or None, 
                                source='viewer', 
                                est_officielle=True
                            )
                        if nom_fr:
                            config.TRADUCTIONS_FR[nom_interne] = nom_fr
                            logger.info(f"   üá´üá∑ Traduction FR: {nom_fr}")
                        if nom_en:
                            logger.info(f"   üá¨üáß Traduction EN: {nom_en}")
                    
                    # D√©finir le filtre bas√© sur le type
                    if type_serie == 'ln':
                        new_serie['filtre'] = 'ln_only'
                        new_serie['type'] = 'ln'
                    elif type_serie == 'manga':
                        new_serie['filtre'] = 'manga_only'
                    # Si pas de type, pas de filtre (comportement par d√©faut = manga)
                    
                    # Si l'URL contient /dp/ASIN, extraire l'ASIN comme r√©f√©rence
                    if url and '/dp/' in url:
                        import re
                        match = re.search(r'/dp/([A-Z0-9]{10})', url)
                        if match:
                            asin = match.group(1)
                            new_serie['asin_reference'] = asin
                            new_serie['urls_supplementaires'] = [url]
                            type_label = f", type: {type_serie}" if type_serie else ""
                            logger.info(f"‚òÅÔ∏è  Nouvelle s√©rie (Gist): {nom} (ASIN ref: {asin}{type_label})")
                        else:
                            logger.info(f"‚òÅÔ∏è  Nouvelle s√©rie (Gist): {nom}")
                    elif url:
                        # URL de recherche classique
                        new_serie['url_suffix'] = url
                        logger.info(f"‚òÅÔ∏è  Nouvelle s√©rie (Gist): {nom}")
                    else:
                        logger.info(f"‚òÅÔ∏è  Nouvelle s√©rie (Gist): {nom}")
                    
                    config.MANGAS_A_SUIVRE.append(new_serie)
                    modifs += 1
                    liste_modifiee = True
            
            # Vider series_ajoutees apr√®s traitement (m√™me si toutes les s√©ries √©taient d√©j√† pr√©sentes)
            config.GIST_SERIES_CONFIG['series_ajoutees'] = []
            config.GIST_MODIFIED = True
            if liste_modifiee:
                logger.info(f"   üßπ S√©ries int√©gr√©es √† {config.MANGAS_LISTE_FILE}, series_ajoutees vid√©")
            else:
                logger.info(f"   üßπ series_ajoutees vid√© (s√©ries d√©j√† pr√©sentes dans {config.MANGAS_LISTE_FILE})")
        
        # 1d. Importer les traductions personnalis√©es du Gist
        gist_traductions = config.GIST_SERIES_CONFIG.get('traductions', {})
        if gist_traductions:
            for serie_jp, titre_fr in gist_traductions.items():
                if serie_jp and titre_fr:
                    config.TRADUCTIONS_FR[serie_jp] = titre_fr
                    # Sauvegarder en BDD si disponible (erreur ignor√©e si BDD verrouill√©e)
                    if db:
                        try:
                            db.sauvegarder_traduction(serie_jp, titre_fr, source='gist', est_officielle=False)
                        except Exception as e:
                            logger.debug(f"Sauvegarde traduction ignor√©e (BDD): {e}")
                    logger.info(f"‚òÅÔ∏è  Traduction (Gist): {serie_jp[:25]}... ‚Üí {titre_fr}")
            
            # Vider les traductions apr√®s import (elles sont en BDD et dans config.TRADUCTIONS_FR)
            config.GIST_SERIES_CONFIG['traductions'] = {}
            config.GIST_MODIFIED = True
            logger.info(f"   üßπ Traductions import√©es du Gist ({len(gist_traductions)}), traductions vid√©")
    
    # ====== √âTAPE 2: Sauvegarder mangas_liste.json si modifi√© ======
    if liste_modifiee:
        sauvegarder_mangas_liste()
    
    # ====== √âTAPE 3: Charger depuis le fichier local (si pr√©sent) ======
    if not os.path.exists(config.SERIES_CONFIG_FILE):
        return
    
    try:
        with open(config.SERIES_CONFIG_FILE, 'r', encoding='utf-8') as f:
            local_config = json.load(f)
        
        urls_supp = local_config.get('urls_supplementaires', {})
        added = local_config.get('added', [])
        removed = local_config.get('removed', [])
        
        modifs = 0
        
        # 1. Fusionner les URLs suppl√©mentaires avec les s√©ries existantes
        if urls_supp:
            for manga in config.MANGAS_A_SUIVRE:
                nom = manga.get('nom', '')
                if nom in urls_supp:
                    existing_urls = manga.get('urls_supplementaires', [])
                    new_urls = urls_supp[nom]
                    # Fusionner sans doublons
                    all_urls = list(set(existing_urls + new_urls))
                    if all_urls:
                        manga['urls_supplementaires'] = all_urls
                        logger.info(f"üîó {len(new_urls)} URL(s) suppl√©mentaire(s) ajout√©e(s) pour: {nom}")
                        modifs += len(new_urls)
        
        # 2. Ajouter les nouvelles s√©ries
        if added:
            for serie in added:
                nom = serie.get('serie_jp', '')
                if nom and not any(m['nom'] == nom for m in config.MANGAS_A_SUIVRE):
                    config.MANGAS_A_SUIVRE.append({
                        'nom': nom,
                        'url_suffix': serie.get('url_suffix', nom),
                        'urls_supplementaires': serie.get('urls_supplementaires', [])
                    })
                    logger.info(f"‚ûï Nouvelle s√©rie ajout√©e: {nom}")
                    modifs += 1
        
        # 3. Retirer les s√©ries supprim√©es
        if removed:
            config.MANGAS_A_SUIVRE = [m for m in config.MANGAS_A_SUIVRE if m['nom'] not in removed]
            if removed:
                logger.info(f"üóëÔ∏è {len(removed)} s√©rie(s) retir√©e(s)")
                modifs += len(removed)
        
        # 4. Ajouter les traductions personnalis√©es au dictionnaire
        traductions = local_config.get('traductions', {})
        if traductions:
            for serie_jp, titre_fr in traductions.items():
                if serie_jp and titre_fr:
                    config.TRADUCTIONS_FR[serie_jp] = titre_fr
                    logger.info(f"üè∑Ô∏è Traduction ajout√©e: {serie_jp[:30]}... ‚Üí {titre_fr}")
                    modifs += 1
        
        if modifs > 0:
            logger.info(f"üìã Configuration charg√©e depuis {config.SERIES_CONFIG_FILE}")
            # Renommer le fichier pour √©viter de re-appliquer
            backup_name = f"series_config_applied_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            os.rename(config.SERIES_CONFIG_FILE, backup_name)
            logger.info(f"   ‚Üí Fichier renomm√© en {backup_name}")
            
    except (json.JSONDecodeError, IOError) as e:
        logger.warning(f"‚ö†Ô∏è  Erreur lecture {config.SERIES_CONFIG_FILE}: {e}")


def git_push():
    """
    Push les fichiers modifi√©s (BDD + mangas_liste.json) vers le d√©p√¥t Git.
    Utilis√© en fin de run pour sauvegarder les changements.
    """
    try:
        files_to_push = ['manga_alerts.db', 'mangas_liste.json']
        
        # V√©rifier qu'on est dans un repo git
        result = subprocess.run(['git', 'status', '--porcelain'], capture_output=True, text=True, timeout=10)
        if result.returncode != 0:
            logger.warning("   ‚ö†Ô∏è  Pas de d√©p√¥t Git d√©tect√©, skip git push")
            return False
        
        # Add les fichiers modifi√©s
        for f in files_to_push:
            if os.path.exists(f):
                subprocess.run(['git', 'add', f], capture_output=True, timeout=10)
        
        # Commit
        date_str = datetime.now().strftime('%Y-%m-%d %H:%M')
        result = subprocess.run(
            ['git', 'commit', '-m', f'Auto-update {date_str}'],
            capture_output=True, text=True, timeout=10
        )
        
        if 'nothing to commit' in result.stdout:
            logger.info("   ‚ÑπÔ∏è  Rien √† commiter")
            return True
        
        # Push
        result = subprocess.run(['git', 'push'], capture_output=True, text=True, timeout=30)
        if result.returncode == 0:
            logger.info("   ‚úÖ Git push r√©ussi")
            return True
        else:
            logger.warning(f"   ‚ö†Ô∏è  Git push √©chou√©: {result.stderr[:100]}")
            return False
            
    except Exception as e:
        logger.warning(f"   ‚ö†Ô∏è  Erreur git push: {str(e)[:80]}")
        return False
